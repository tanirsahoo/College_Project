# -*- coding: utf-8 -*-
"""PG_RECOMMENDATION.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KPyoNgfUtVyEfX3KnZo9I3XRj-YXZ3k8
"""

from google.colab import files
files.upload()

import pandas as pd
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.compose import ColumnTransformer
import json

# PG list table (no User_id present)
pg_list = pd.read_csv('pg_list_data_fixed.csv')

# Search history table
search_history = pd.read_csv('search_history_data_fixed.csv')

# Define preprocessing pipeline
preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), ['Cost', 'Duration']),
        ('cat', OneHotEncoder(), ['State', 'Type', 'Feature_type'])
    ]
)

# Input: User ID for whom to generate recommendations
user_id = 4  # Change this to test with other users

# Step 4.1: Determine the state searched most frequently by the user
majority_state = (
    search_history[search_history['User_id'] == user_id]
    .groupby('State')
    .size()
    .idxmax()
)

# Step 4.2: Filter PGs from the majority state
filtered_pgs = pg_list[pg_list['State'] == majority_state]

# Step 4.3: Sort the PGs by Cost, Feature_type, and Duration
recommended_pgs = filtered_pgs.sort_values(by=['Cost', 'Feature_type', 'Duration']).head(5)

# Step 5: Convert to JSON format
recommended_pgs_json = recommended_pgs.to_json(orient='records', indent=4)

# Output the JSON
print("Recommended PGs in JSON format:")
print(recommended_pgs_json)